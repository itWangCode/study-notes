# HTTP2.0

改进传输性能,实现低延迟和高吞吐量。

现有的网站和应用，无需做任何更改都可以在HTTP2.0上跑起来

HTTP2.0的目标:

1.支持请求与响应的多路复用来减少延迟  
2.通过压缩HTTP首部字段将协议开销降至最低。  
3.同时增加对请求优先级和服务器推送的支持

## 二进制分帧层**

HTTP的语义，包括各种动词，方法，首部都不受影响，不同的是传输期间对他们的编码方式变了。HTTP1.x以换行符作为纯文本的分隔符，而HTTP2.0将所有传输的信息分隔为更小的消息和帧，并对他们采用二进制格式的编码

- 流,消息,帧:

流：已建立的连接上的双向字节流

消息：与逻辑消息对应的完整的一系列数据帧

帧： HTTP2.0通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流

所有HTTP2.0通信都在同一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。

- 几个概念点：

  1. 所有的通信都在一个TCP连接上完成
  2. 流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标示符（1，2，。。。N）；
  3. 消息是指逻辑上的HTTP消息，比如请求，相应等，由一或多个帧组成
  4. 帧是最小的通信单位，承载着特定类型的数据，如HTTP首部，负荷，等等。

## 多向请求与响应

巨大的性能提升：

  1. 可以并行交错地发送请求，请求之间互不影响
  2. 可以并行交错地发送响应，响应之间互不影响
  3. 只使用一个连接即可并行发送多个请求和响应
  4. 消除不必要的延迟，从而减少页面加载的时间
  5. 不必再为绕过HTTP1.x限制而多做很多工作

## 请求优先级

每个流都可以带有一个31比特的优先值。0表示最高优先级，2（31）- 1表示最低优先级。

HTTP2.0没有规定处理优先级的具体算法。策略：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据。

服务器可以而且应该交错发送不同优先级别的帧。既避免队首阻塞，又高效利用底层连接。

## 每个来源一个连接

不仅减少网络延迟，还有助于提高吞吐量和降低运营成本。

## 流量控制

优先级可以决定交付次序，而流量控制则可以控制HTTP2.0连接中每个流占用的资源：接收方可以针对特定的流广播较低的窗口大小，以限制它的传输速度。

HTTP2.0为数据流和连接的流量控制提供了一个简单的机制：

  1. 流量控制基于每一跳进行，而非端到端的控制
  2. 流量控制基于窗口更新帧进行，即接收广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节
  3. 流量控制窗口大小通过WINDOW_UPDATE帧更新，这个字段指定了流ID和窗口大小递增值
  4. 流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口的大小。
  5. 流量控制可以由接收方禁用，包括针对个别的流和针对整个连接

## 服务器推送

在HTTP2.0中，把资源通过HTTP推送给客户端，有以下好处：

  1. 客户端可以缓存推送过来的资源
  2. 客户端可以拒绝推送过来的资源
  3. 推送资源可以由不同的页面共享
  4. 服务器可以按照优先级推送资源

理论上，除了只有某页面需要的插入资源，之外的所有应用都应该使用HTTP2.0服务器推送。

推送资源直接进入客户端，不存在客户端API或Javascript回调方法等通知机制，可以用于确定资源何时到达。

## 首部压缩

- HTTP2.0在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送
- 首部表在HTTP2.0的连续存续期内始终存在，由客户端和服务器共同渐进地更新
- 每个新的首部键-值对要么被追加到当前表的末尾，要么替换表中之前的值。

## 有效的HTTP2.0升级与发现

## 部署

参考NGINX白皮书，NGINX配置HTTP2.0官方指南 <https://www.nginx.com/blog/nginx-1-9-5/。>

部署博客：<https://www.liangzl.com/get-article-detail-594.html>

## http2对比http1

### 多路复用

HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；

HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；

HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

### 二进制分帧

单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大

由于 TCP 连接的减少而使网络拥塞状况得以改善,同时慢启动时间的减少,使拥塞和丢包恢复速度更快

### 首部压缩

### 服务器推送

服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度
