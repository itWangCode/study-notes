# HTTP2.0

改进传输性能,实现低延迟和高吞吐量。

现有的网站和应用，无需做任何更改都可以在HTTP2.0上跑起来

## 二进制

HTTP的语义，包括各种动词，方法，首部都不受影响，不同的是传输期间对他们的编码方式变了。

在 HTTP/1.1 版中，报文的头信息必须是文本（ASCII 编码），数据体可以是文本，也可以是 二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制

所有的通信都在一个TCP连接上完成

## 分帧数据流

流：已建立的连接上的双向字节流。流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标示符（1，2，。。。N）；

消息：与逻辑消息对应的完整的一系列数据帧。消息是指逻辑上的HTTP消息，比如请求，相应等，由一或多个帧组成

帧： HTTP2.0通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流。帧是最小的通信单位，承载着特定类型的数据，如HTTP首部，负荷，等等。

所有HTTP2.0通信都在同一个连接上完成，这个连接可以承载任意数量的双向数据流。

HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的 请求。因此，必须要对数据包做标记，指出它属于哪个请求。HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。每 个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 ID ，用来区分它属于哪个数据流。

## 多路复用

多向并行请求与响应。可以并行交错地发送请求和响应，请求响应之间互不影响

只使用一个连接即可并行发送多个请求和响应

消除不必要的延迟，从而减少页面加载的时间

HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；

HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；

HTTP/2多个请求可同时在一个连接上并行执行。不用按照HTTP1需要顺序一一发送，这样就避免了"队头堵塞"的问题。某个请求任务耗时严重，不会影响到其它连接的正常执行；

```
在 HTTP/1 中，每次请求都会建立一次HTTP连接，也就是我们常说的3次握手4次挥手，这个过程在一次请求过程中占用了相当长的时间，即使开启了 Keep-Alive ，解决了多次连接的问题，但是依然有两个效率上的问题：

第一个：串行的文件传输。当请求a文件时，b文件只能等待，等待a连接到服务器、服务器处理文件、服务器返回文件，这三个步骤。我们假设这三步用时都是1秒，那么a文件用时为3秒，b文件传输完成用时为6秒，依此类推。（注：此项计算有一个前提条件，就是浏览器和服务器是单通道传输）
第二个：连接数过多。我们假设Apache设置了最大并发数为300，因为浏览器限制，浏览器发起的最大请求数为6，也就是服务器能承载的最高并发为50，当第51个人访问时，就需要等待前面某个请求处理完成。
HTTP/2的多路复用就是为了解决上述的两个性能问题。
在 HTTP/2 中，有两个非常重要的概念，分别是帧（frame）和流（stream）。
帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。
多路复用，就是在一个 TCP 连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。
```

## 首部压缩

HTTP2.0在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送

首部表在HTTP2.0的连续存续期内始终存在，由客户端和服务器共同渐进地更新

每个新的首部键-值对要么被追加到当前表的末尾，要么替换表中之前的值。

一方面，头信息使用 gzip 或 compress 压缩后再发送；

另一方面， 客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引 号，这样就能提高速度了。

## 服务器推送

在HTTP2.0中，把资源通过HTTP推送给客户端，有以下好处：

  1. 客户端可以缓存推送过来的资源
  2. 客户端可以拒绝推送过来的资源
  3. 推送资源可以由不同的页面共享
  4. 服务器可以按照优先级推送资源

理论上，除了只有某页面需要的插入资源，之外的所有应用都应该使用HTTP2.0服务器推送。

推送资源直接进入客户端，不存在客户端API或Javascript回调方法等通知机制用于确定资源何时到达。

HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送。

使用服务器推送，提前给客户端推送必要的资源 ，这样就可以相对减少一些延迟时间。

这里需要注意的是 http2 下服务器主动推送的是静态资源，和 WebSocket 以及使用 SSE 等方式向客户端发送即时数据的推送是不同的。

服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度

## 请求优先级

每个流都可以带有一个31比特的优先值。0表示最高优先级，2（31）- 1表示最低优先级。

HTTP2.0没有规定处理优先级的具体算法。策略：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据。

服务器可以而且应该交错发送不同优先级别的帧。既避免队首阻塞，又高效利用底层连接。

## 每个来源一个连接

不仅减少网络延迟，还有助于提高吞吐量和降低运营成本。

## 流量控制

优先级可以决定交付次序，而流量控制则可以控制HTTP2.0连接中每个流占用的资源：接收方可以针对特定的流广播较低的窗口大小，以限制它的传输速度。

HTTP2.0为数据流和连接的流量控制提供了一个简单的机制：

  1. 流量控制基于每一跳进行，而非端到端的控制
  2. 流量控制基于窗口更新帧进行，即接收广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节
  3. 流量控制窗口大小通过WINDOW_UPDATE帧更新，这个字段指定了流ID和窗口大小递增值
  4. 流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口的大小。
  5. 流量控制可以由接收方禁用，包括针对个别的流和针对整个连接

## 部署

参考NGINX白皮书，NGINX配置HTTP2.0官方指南 <https://www.nginx.com/blog/nginx-1-9-5/。>

部署博客：<https://www.liangzl.com/get-article-detail-594.html>
