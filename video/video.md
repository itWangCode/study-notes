# 视频播放

[69 篇文章带你系统性的学习音视频开发（收藏起来假期看）](https://juejin.cn/post/7236929075251445817)

[「1.4万字」玩转前端 Video 播放器 | 多图预警](https://juejin.cn/post/6850037275579121671)

[浏览器中的音视频知识总结v1.0(工作中需要和视频打交道必看！)](https://juejin.cn/post/7002288264413446157?searchId=20230801145246316C72E0826F5F745D7D#heading-35)

[为什么视频网站的视频链接地址是blob？](https://juejin.cn/post/6844903880774385671)

[我们为什么使用DASH](https://www.bilibili.com/read/cv855111/)

[浏览器中的音视频知识总结v1.0(工作中需要和视频打交道必看！)](https://juejin.cn/post/7002288264413446157)

## 浏览器自定义播放器

依赖于标签

```html
<video controls poster="1.jpg" src="1.mp4" loop muted></video>
<audio controls src="1.mp3"></audio>
```

[从零实现一个自定义 HTML5 播放器](https://juejin.cn/post/6844903487910723592)

[自定义H5 video 播放器](https://juejin.cn/post/6844903976312242183)

## 音视频第三方

[我用ChatGPT做直播技术选型，卷死了同事](https://juejin.cn/post/7202265125541642299)

[主流的第三方直播SDK对比（腾讯云、即构、阿里云、声网、网易云信、网宿）](https://juejin.cn/post/7166424083054198792)

[移动直播技术知多少：基础原理解析 & 腾讯云直播接入](https://juejin.cn/post/6844904136324956174#heading-0)

声网

即构

腾讯云

阿里云

## flv.js

```
支持播放 H.264 + AAC / MP3 编码的 FLV 文件；
支持播放多段分段视频；
支持播放 HTTP FLV 低延迟实时流；
支持播放基于 WebSocket 传输的 FLV 实时流；
兼容 Chrome，FireFox，Safari 10，IE11 和 Edge；
极低的开销，支持浏览器的硬件加速。

MP3 音频编解码器无法在 IE11/Edge 上运行；
HTTP FLV 直播流不支持所有的浏览器。
```

flv.js 的工作原理是将 FLV 文件流转换为 ISO BMFF（Fragmented MP4）片段，然后通过 Media Source Extensions API 将 mp4 段喂给 HTML5 `<video>` 元素。

## MediaSource

MSE(Media Source Extensions API)

媒体源扩展 API（MSE）提供了实现无插件且基于 Web 的流媒体的功能。使用 MSE，媒体串流能够通过 JavaScript 创建，并且能通过使用 `<audio> 和 <video>` 元素进行播放。

## video.js

videojs-flash

video.js + flv.js

## 阿里库

<https://helpcdn.aliyun.com/document_detail/125570.html?spm=a2c4g.11186623.6.1170.1b995488xW7f5O>

## FFMPEG

FFMPE是音视频处理最常用的开源软件，

## 分辨率

屏幕是由一个个像素点组成的，我们常见的1080p，是指屏幕竖直方向有1080个像素，共有1920列，一共207万像素。2K，2560x1440，共369万像素。

## 码率

视频码率是指存储单位时间视频需要的数据大小，单位是 kbps，码率越大，单位时间填充的数据就越多，通常视频质量就越高。

但是码率并不是越大就越好，码率设置超过一定的大小，对视频画质的提升已不太明显，肉眼已经看不出区别，但是视频大小会增加很多。所以设置合适的码率就行。

## 视频编码

经过编码之后，视频由一帧帧的图片，变成了一串串让人看不懂的二进制代码，因为编码的方式(算法)的不同，所以就有了编码格式的区分。常见的编码格式有

跟音频编码一样，视频编码最重要的目的也是为了进行数据压缩，以此来降低数据传输和存储成本。

```
H.264,
H.265,
H.266,
MPEG-4,
VP8
```

```
H.264，也被称为高级视频编码（Advanced Video Coding，简称 AVC），是一种被广泛使用的高精度视频的录制、压缩和发布格式。该标准引入了一系列新的能够大大提高压缩性能的技术，并能够同时在高码率端和低码率端大大超越以前的诸标准。

H.265，也被称为高效率视频编码（High Efficiency Video Coding，简称 HEVC），是 H.264 的继任者。HEVC 被认为不仅提升图像质量，同时也能达到 H.264 两倍的压缩率（等同于同样画面质量下比特率减少了 50%），可支持 4K 分辨率甚至到超高画质电视，最高分辨率可达到 8192×4320（8K 分辨率），这是目前发展的趋势。

H.266，也被称为多功能视频编码（Versatile Video Coding，简称 VVC），是 H.265 的继任者。VVC 对 8K 超高清、屏幕、高动态和 360 度全景视频等新的视频类型以及自适应带宽和分辨率的流媒体和实时通信等应用有了更好的支持。根据最近的 JVET 官方主观测试结果，VVC 的平均编码性能相对 HEVC 的提高已经可以达到 49%
```

我们前端开发只需要记住一点，主流浏览器支持的视频编码格式是h264。

前端开发的需要记住，视频编码为h264，音频编码为aac的MP4文件在各大浏览器都能播放，因为h264编码格式虽然有版权，但是可以免费使用。

相对于 H.265，根据官方主观测试结果，H.266 的平均编码性能提高了 49%

## 音频编码

常见的编码方式有：

```
WAV、
MP3
AAC
```

格式。

## 音视频封装格式

封装格式往往是与视频编码无关的，一个mp4文件，里面的视频流编码可以是h264，也可以是mpeg-4，所以就会出现，同样都是mp4文件，有的浏览器可以放，有的浏览器就放不了的问题，因为能不能放是由视频码流的编码格式决定的。

我们把视频数据、音频数据打包到一起，然后再添加一些基本信息，例如分辨率、时长、标题等，构成一个文件，这个文件称为封装格式。常见的封装格式有

```
MP4,
FLV
M3U8
TS
MOV,
MPEG,
WEBM
```

等。

## 传输协议

- RTMP协议

RTMP(Real Time Messaging Protocol)实时消息传送协议是Adobe Systems公司为Flash播放器和服务器之间音频、视频和数据传输 开发的开放协议。是我们市面上绝大多数部分PC秀场使用的技术栈, 他有低延迟(2秒左后), 稳定性高, 技术完善, 高支持度, 编码兼容性高等特点.

- HTTP-FLV协议

FLV (Flash Video) 是 Adobe 公司推出的另一种视频格式，是一种在网络上传输的流媒体数据存储容器格式。HTTP-FLV 即将流媒体数据封装成 FLV 格式，然后通过 HTTP 协议传输给客户端。HTTP-FLV这种方式较RTMP协议好的就是它采用公共的HTTP80端口, 有效避免被防火墙拦截, 可以通过 HTTP 302 跳转灵活调度/负载均衡，支持使用 HTTPS 加密传输，但它也有缺点, 视频的内容会缓存到用户本地, 保密性不好. HTTP-FLV的整体流程和RTMP协议一致, 但在客户端播放有些差异, 在MSE出现以前市场上一般都是用flash播放器去播放, MSE出现以后以及推广HTML5播放器的原因, 市场上开始使用JS软解FLV的方式, 通过HTMLVideoElement去播放.

- HTTP-HLS协议

基于HTTP

HLS （HTTP Live Streaming）, 是由 Apple 公司实现的基于 HTTP 的媒体流传输协议。

HLS以ts为传输格式，m3u8为索引文件（文件中包含了所要用到的ts文件名称，时长等信息，可以用播放器播放，也可以用vscode之类的编辑器打开查看）

在移动端大部分浏览器都支持，也就是说你可以用video标签直接加载一个m3u8文件播放视频或者直播，但是在pc端，除了苹果的Safari，需要引入库来支持。

移动端支持良好, 现在已经成为移动端H5直播的主要技术

- HTTP-DASH协议

[DASH](./DASH.md)

- KCP协议

## 视频编码优化

- 码率分配模式

```
码率分配模式是指在对视频进行编码时如何针对画面情况来进行码率的分配。码率分配模式一般有
CBR：Constant Bitrate，固定比特率、
VBR：Variable Bitrate，动态比特率
ABR：Average Bitrate，平均比特率，是 VBR 的一种插值参数、
CRF：Constant Rate Factor，恒定码率系数
等几种方式
```

- 设置 B 帧优化码率

- 调整 GOP 长度优化码率

- 尽量使用 HEVC 编码

- 合理使用软编和硬编优化编码

## 画质增强

- 锐化

图像锐化是补偿图像的轮廓，增强图像的边缘及灰度跳变的部分，使图像变得清晰，分为空间域处理和频域处理两类。

图像锐化是为了突出图像上地物的边缘、轮廓，或某些线性目标要素的特征。这种方法提高了地物边缘与周围像元之间的反差，因此也被称为边缘增强。

```
常用的图像锐化的方法有：
USM（Unsharpen Mask）锐化
拉普拉斯（Laplace）锐化
高通滤波
```

- 降噪

- 防抖

- 超分

- 对焦优化

- 颜色优化

- 模糊检测

## 发布优化

转码成功率优化

视频大文件分片上传

就近上传 CDN

上传网络错误重试与监测

图像数据处理速度优化: libyuv 是 Google 开源的 YUV 图像处理库，实现对各种 YUV 和 RGB 数据之间的转换，包括数据转换、裁剪、缩放、旋转。它是跨平台的，支持在多种操作系统和 CPU 架构上进行编译运行，支持 SSE、AVX、NEON 等 SIMD 指令加速。

## 播放器优化

视频从服务端到播放器播放的过程中会经过网络传输、解封装、音视频解码、音视频同步、音视频渲染等阶段，每个阶段遇到了问题都可能造成播放错误

## 视频秒开优化

- 预加载

- 封面图清晰度降级:

在短视频业务实现中，我们通常会加载一张视频首帧的封面图作为占位图，等待播放器完成视频首帧渲染时隐藏掉这张封面图完成画面衔接给用户一种流畅的体验。

- DNS 解析

采用 HTTPDNS 是优化 DNS 解析的常用方案

- TCP

TFO(TCP Fast Open) 是用来加速连续 TCP 连接的数据交互的 TCP 协议扩展，是对 TCP 握手过程的一种简化。它的原理是：在 TCP 三次握手的过程中，当用户首次访问 Server 时，发送 SYN 包，Server 根据用户 IP 生成 Cookie（已加密），并与 SYN-ACK 一同发回 Client；当 Client 随后重连时，在 SYN 包携带 TCP Cookie；如果 Server 校验合法，则在用户回复 ACK 前就可以直接发送数据；否则按照正常三次握手进行。

根据测试数据，TFO 可以减少 15% 的 HTTP 传输延迟，全页面的下载时间平均节省 10%，最高可达 40%。

- 通过 TCP 预连接和连接复用优化建连时长

用户滑的慢时，可以预链接。

但是，当检测到用户是快速滑动时，可以及时中断预连接的 Socket，避免网络带宽争抢。

- 预渲染首帧代替封面图

- 其他

## 播放器卡顿优化

- 码率调控

H.265 相对于 H.264 压缩效率更高，在保持一定画质的情况下使用 H.265 替换 H.264 可以降低码率。

- 播放器策略

- 推流端策略

- CDN策略

在 CDN 服务端来控制下发视频数据的带宽和速度。比如，在拉取直播流时，服务端将以数倍于平时带宽的速度下发前面缓存的若干时长的数据给客户端，这样播放器在开播时能较快的拉取比较充足的数据，防止开播卡顿。

## IOS视频API

- Video Toolbox Framework：

视频硬编码和硬解码

- Core Media Framework：

定义和封装了AVFoundation 等更上层的媒体框架需要的媒体处理流水线（包含时间信息）以及其中使用的接口和数据类型

- Core Video Framework：

主要用于支持数字视频及数字图像帧的处理，提供基于处理 Pipeline 的 API，并且同时支持 Metal 和 OpenGL。

- AVFoundation Framework：

更上层的面向对象的一个音视频处理框架。它提供了音视频资源管理、相机设备管理、音视频处理、系统级音频交互管理的能力，功能非常强大。如果对其功能进行细分，可以分为如下几个模块：

Assets，音视频资源管理。
Playback，媒体播放及自定义播放行为支持。
Capture，内置及外置的相机、麦克风等采集设备管理，图片、音视频录制。
Editing，音视频编辑。
Audio，音频播放、录制和处理，App 系统音频行为配置。
Speech，文本语音转换。
